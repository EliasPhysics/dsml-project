{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "from model import TimeSeriesTransformer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from psd import power_spectrum_error, compute_power_spectrum\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "import csv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e69fcdbcb8b4c8b",
   "metadata": {},
   "source": [
    "First, we define the dataset class, that prepares training data from the long trajectory provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519a91c92521f43a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Just some helper functions\n",
    "\n",
    "def generate_square_subsequent_mask(dim1: int, dim2: int):\n",
    "    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)\n",
    "\n",
    "\n",
    "def get_indices_entire_sequence(data: Tensor, window_size: int, step_size: int) -> list:\n",
    "\n",
    "    start_index = 0\n",
    "    stop_index = window_size\n",
    "\n",
    "    list_indices = []\n",
    "\n",
    "    # go through all available timeframes\n",
    "    while stop_index < len(data):\n",
    "        list_indices.append((start_index, stop_index))\n",
    "\n",
    "        start_index += step_size\n",
    "        stop_index += step_size\n",
    "\n",
    "    return list_indices\n",
    "\n",
    "\n",
    "def read_data(data_dir:str) -> Tensor:\n",
    "    array = np.load(data_dir)\n",
    "    print(f\"Loaded data shape: {array.shape}\")\n",
    "    \n",
    "    return torch.from_numpy(array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aee9b7b9c55632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data: torch.tensor,\n",
    "                 indices: list,\n",
    "                 enc_seq_len: int,\n",
    "                 dec_seq_len: int,\n",
    "                 target_seq_len: int\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.indices = indices\n",
    "        self.data = data\n",
    "        self.enc_seq_len = enc_seq_len\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a tuple with 3 elements:\n",
    "        1) src (the encoder input)\n",
    "        2) trg (the decoder input)\n",
    "        3) trg_y (the target)\n",
    "        \"\"\"\n",
    "        # Get the first element of the i'th tuple in the list self.indicesasdfas\n",
    "        start_idx = self.indices[index][0]\n",
    "\n",
    "        # Get the second (and last) element of the i'th tuple in the list self.indices\n",
    "        end_idx = self.indices[index][1]\n",
    "\n",
    "        sequence = self.data[start_idx:end_idx]\n",
    "\n",
    "        src, trg, trg_y = self.get_src_trg(\n",
    "            sequence=sequence,\n",
    "            enc_seq_len=self.enc_seq_len,\n",
    "            target_seq_len=self.target_seq_len\n",
    "        )\n",
    "\n",
    "        return src, trg, trg_y\n",
    "\n",
    "    def get_src_trg(\n",
    "            self,\n",
    "            sequence: torch.Tensor,\n",
    "            enc_seq_len: int,\n",
    "            target_seq_len: int\n",
    "    ) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
    "\n",
    "        assert len(\n",
    "            sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n",
    "\n",
    "        # encoder input\n",
    "        src = sequence[:enc_seq_len]\n",
    "        trg = sequence[enc_seq_len - 1:len(sequence) - 1]\n",
    "        assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n",
    "\n",
    "        # The target sequence against which the model output will be compared to compute loss\n",
    "        trg_y = sequence[-target_seq_len:]\n",
    "        assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n",
    "\n",
    "        return src, trg, trg_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a67a178cb823ae",
   "metadata": {},
   "source": [
    "Now we define the TimeSeriesTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f0ac2a6ffbd704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 dec_seq_len: int,\n",
    "                 d_model: int = 512,\n",
    "                 n_encoder_layers: int = 4,\n",
    "                 n_decoder_layers: int = 4,\n",
    "                 dropout: float = 0.2,\n",
    "                 max_seq_len: int = 512,\n",
    "                 dim_feedforward_encoder: int = 2048,\n",
    "                 n_heads: int = 8,\n",
    "                 dim_feedforward_decoder: int = 2048,\n",
    "                 num_predicted_features: int = 3\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "        # positional encoder\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # create array for positional encoding\n",
    "        position_counter = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        # taken from the positional encoding torch tutorial\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # create positional encoding shift to add to the sequential data\n",
    "        pos_encoding = torch.zeros(1, max_seq_len, d_model)\n",
    "        pos_encoding[0, :, 0::2] = torch.sin(position_counter * div_term)\n",
    "        pos_encoding[0, :, 1::2] = torch.cos(position_counter * div_term)\n",
    "\n",
    "        # this makes torch register the positional encoding as non-trainable parameter\n",
    "        self.register_buffer('pe', pos_encoding)\n",
    "\n",
    "        # encoder\n",
    "\n",
    "\n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features=input_size,\n",
    "            out_features=d_model\n",
    "        )\n",
    "\n",
    "        # Create positional encoder from other module\n",
    "\n",
    "        # now build encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead = n_heads,\n",
    "            dim_feedforward=dim_feedforward_encoder,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # stack encoder layers to obtain Encoder\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=n_encoder_layers,\n",
    "            norm=None\n",
    "        )\n",
    "\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "\n",
    "        self.decoder_input_layer = nn.Linear(\n",
    "            in_features=num_predicted_features,\n",
    "            out_features=d_model,\n",
    "        )\n",
    "\n",
    "        # create one decoder layer\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward_decoder,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # stack the decoder layers\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=decoder_layer,\n",
    "            num_layers=n_decoder_layers,\n",
    "            norm=None\n",
    "        )\n",
    "\n",
    "        self.linear_mapping = nn.Linear(\n",
    "            in_features=d_model,\n",
    "            out_features=num_predicted_features\n",
    "        )\n",
    "\n",
    "    def pos_encoding(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, enc_seq_len, dim_val]\n",
    "\n",
    "        returns: Tensor, shape [batch_size,enc_seq_len, dim_val]\n",
    "        \"\"\"\n",
    "        #print(f\"forward tensor shape: {x.shape}, pos enc shape: {self.pe[:, :x.size(1)].shape}\")\n",
    "        x = x + self.pe[:,:x.size(1)]\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Tensor=None, tgt_mask: Tensor=None) -> Tensor:\n",
    "\n",
    "        src = self.encoder_input_layer(src)\n",
    "\n",
    "        # Pass through the positional encoding layer\n",
    "        # src = src.unsqueeze(0)\n",
    "        pos_encoded_src = self.pos_encoding(src)\n",
    "\n",
    "        encoder_output = self.encoder(\n",
    "            src=pos_encoded_src\n",
    "        )\n",
    "\n",
    "        tgt = self.decoder_input_layer(tgt)\n",
    "\n",
    "        decoder_output = self.decoder(\n",
    "            tgt=tgt,\n",
    "            memory=encoder_output,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=src_mask\n",
    "        )\n",
    "\n",
    "        decoder_output = self.linear_mapping(decoder_output)\n",
    "\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c29e517086c9f",
   "metadata": {},
   "source": [
    "Now the training procedure of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e5882236c7bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_TimeSeriesTransformer(data_path, args):\n",
    "    # Training parameters\n",
    "    epochs = args[\"epochs\"]\n",
    "    batch_size = args[\"batch_size\"]\n",
    "\n",
    "    # Initialize data\n",
    "    data = utils.read_data(data_path)\n",
    "\n",
    "    ## Params from args\n",
    "    dec_seq_len = args[\"dec_seq_len\"]\n",
    "    enc_seq_len = args[\"enc_seq_len\"]\n",
    "    output_seq_len = args[\"output_seq_len\"]\n",
    "    window_size = args[\"window_size\"]\n",
    "    step_size = args[\"step_size\"]\n",
    "\n",
    "\n",
    "    training_indices = utils.get_indices_entire_sequence(\n",
    "        data=data,\n",
    "        window_size=window_size,\n",
    "        step_size=step_size)\n",
    "\n",
    "    training_data = TransformerDataset(data=data,\n",
    "                                     indices=training_indices,\n",
    "                                     enc_seq_len=enc_seq_len,\n",
    "                                     dec_seq_len=dec_seq_len,\n",
    "                                     target_seq_len=output_seq_len)\n",
    "\n",
    "    training_data = DataLoader(training_data, batch_size,shuffle=True)\n",
    "\n",
    "    model = TimeSeriesTransformer(\n",
    "        input_size=data.shape[1],  # Assuming 'data' is already loaded\n",
    "        dec_seq_len=args[\"dec_seq_len\"],\n",
    "        d_model=args[\"dim_val\"],\n",
    "        n_encoder_layers=args[\"n_encoder_layers\"],\n",
    "        n_decoder_layers=args[\"n_decoder_layers\"],\n",
    "        dropout=0.2,\n",
    "        max_seq_len=args[\"max_seq_len\"],\n",
    "        dim_feedforward_encoder=args[\"in_features_encoder_linear_layer\"],\n",
    "        n_heads=args[\"n_heads\"],\n",
    "        dim_feedforward_decoder=args[\"in_features_decoder_linear_layer\"],\n",
    "        num_predicted_features= data.shape[1] # Assuming prediction targets match input features\n",
    "    )\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters())\n",
    "    criterion = torch.nn.HuberLoss()\n",
    "\n",
    "    # Make src mask for decoder with size:\n",
    "    # [batch_size*n_heads, output_sequence_length, enc_seq_len]\n",
    "    src_mask = utils.generate_square_subsequent_mask(\n",
    "        dim1=output_seq_len,\n",
    "        dim2=enc_seq_len\n",
    "        )\n",
    "\n",
    "    # Make tgt mask for decoder with size:\n",
    "    # [batch_size*n_heads, output_sequence_length, output_sequence_length]\n",
    "    tgt_mask = utils.generate_square_subsequent_mask(\n",
    "        dim1=output_seq_len,\n",
    "        dim2=output_seq_len\n",
    "        )\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # Iterate over all epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        # Iterate over all (x,y) pairs in training dataloader\n",
    "        for i, (src, tgt, tgt_y) in enumerate(training_data):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            #print(src.shape, tgt.shape)\n",
    "\n",
    "            # Make forecasts\n",
    "            #print(f\"src: {src.shape}, tgt: {tgt.shape}\")\n",
    "            prediction = model(src=src, tgt=tgt, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "\n",
    "            # Compute and backprop loss\n",
    "            loss = criterion(tgt_y, prediction)\n",
    "            losses.append(loss.detach())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Take optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "        # Iterate over all (x,y) pairs in validation dataloader\n",
    "\n",
    "\n",
    "\n",
    "    model_name = args[\"model_name\"]\n",
    "    torch.save(model.state_dict(), f\"models/{model_name}.pth\")\n",
    "\n",
    "    plt.plot(range(len(losses)),losses)\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.savefig(f\"plots/training_{model_name}.png\")\n",
    "\n",
    "    # Save hyperparameters as CSV\n",
    "    with open(f\"models/{model_name}.csv\", \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Name\", \"Age\"])  # Column headers\n",
    "        for key, value in args.items():\n",
    "            writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe388580ff51053a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we want to test our model by generating new data time series data from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da890cfaea74d9b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_TimeSeriesTransformer(data_path_train,data_path,args):\n",
    "\n",
    "    # data for comparison/ validation\n",
    "    data_validation = utils.read_data(data_path)\n",
    "    \n",
    "    # numver of warmup steps\n",
    "    warmup_steps = 100\n",
    "\n",
    "    model_name = args[\"model_name\"]\n",
    "    enc_seq_len = args[\"enc_seq_len\"]\n",
    "    output_seq_len = args[\"output_seq_len\"]\n",
    "\n",
    "    data_train = utils.read_data(data_path_train)\n",
    "\n",
    "    # Load the trained model\n",
    "    model_path = f\"models/{model_name}.pth\"  # Change path if needed\n",
    "    model = TimeSeriesTransformer(\n",
    "        input_size=data_validation.shape[1],  # Assuming 'data' is already loaded\n",
    "        dec_seq_len=args[\"dec_seq_len\"],\n",
    "        d_model=args[\"dim_val\"],\n",
    "        n_encoder_layers=args[\"n_encoder_layers\"],\n",
    "        n_decoder_layers=args[\"n_decoder_layers\"],\n",
    "        dropout=0.2,  # Default value\n",
    "        max_seq_len=args[\"max_seq_len\"],\n",
    "        dim_feedforward_encoder=args[\"in_features_encoder_linear_layer\"],\n",
    "        n_heads=args[\"n_heads\"],\n",
    "        dim_feedforward_decoder=args[\"in_features_decoder_linear_layer\"],\n",
    "        num_predicted_features= data_validation.shape[1]  # Assuming prediction targets match input features\n",
    "    )\n",
    "\n",
    "    # load trained model\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        print(\"Model loaded successfully!\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "    # take some random initial condition from the training set\n",
    "    start = random.randrange(len(data_train)-enc_seq_len-output_seq_len-1)\n",
    "    initial_condition = data_train[start:start+enc_seq_len + output_seq_len]\n",
    "    initial_condition = initial_condition.unsqueeze(0)\n",
    "\n",
    "    print(\"Creating new time series\")\n",
    "\n",
    "\n",
    "    # first warm up the model to get away from initial condition  \n",
    "    warmup_time_series = initial_condition\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup_steps):\n",
    "            # devide data into src and tgt (encoder and decoder input)\n",
    "            src = warmup_time_series[:, :enc_seq_len]\n",
    "            tgt = warmup_time_series[:, enc_seq_len - 1:warmup_time_series.shape[1] - 1]\n",
    "\n",
    "            # calculate output\n",
    "            output = model(src=src, tgt=tgt)\n",
    "\n",
    "\n",
    "            warmup_time_series = torch.cat((warmup_time_series, output[:,-1].unsqueeze(0)), dim=1)\n",
    "            warmup_time_series = warmup_time_series[:, 1:]\n",
    "\n",
    "    \n",
    "    generated_time_series = warmup_time_series\n",
    "    current_generated_time_series = warmup_time_series\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in tqdm(range(int(data_validation.shape[0]))):\n",
    "            src = current_generated_time_series[:, :enc_seq_len]\n",
    "            tgt = current_generated_time_series[:, enc_seq_len - 1:current_generated_time_series.shape[1] - 1]\n",
    "\n",
    "            output = model(src=src, tgt=tgt)\n",
    "            generated_time_series = torch.cat((generated_time_series, output[:,-1].unsqueeze(0)), dim=1)\n",
    "            current_generated_time_series = torch.cat((current_generated_time_series, output[:,-1].unsqueeze(0)), dim=1)\n",
    "            current_generated_time_series = current_generated_time_series[:, 1:]\n",
    "\n",
    "\n",
    "    # cute time series to be the right length\n",
    "    generated_time_series = generated_time_series[:,:data_validation.shape[0]]\n",
    "\n",
    "\n",
    "\n",
    "    # Create a 3D figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    generated_trajectory = torch.transpose(generated_time_series.squeeze(0),dim0=0,dim1=1)\n",
    "    np.save(f\"data/generated_trajectory_{model_name}.npy\", generated_time_series)\n",
    "\n",
    "    x,y,z = generated_trajectory[:3]\n",
    "    x_or,y_or,z_or = torch.transpose(data_validation[:,:3],dim0=0,dim1=1)\n",
    "\n",
    "    # Plot the trajectory\n",
    "    ax.plot(x, y, z, label='3D Trajectory', color='b',alpha=0.7)\n",
    "    ax.plot(x_or, y_or, z_or, label='Original Trajectory', color='r',alpha=0.2)\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_title(\"3D Trajectory Plot\")\n",
    "\n",
    "    # Show the legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.savefig(f\"plots/3D_Trajectory_model{model_name}.png\")\n",
    "    plt.show()\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed703c3115e9adb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def analyze_generated_trajectories(model_name,data_validation_path):\n",
    "\n",
    "    generated_trajectory = utils.read_data(f\"data/generated_trajectory_{model_name}.npy\")\n",
    "    test_trajectory = utils.read_data(data_validation_path)\n",
    "\n",
    "    freqs = np.fft.rfftfreq(generated_trajectory.shape[1])\n",
    "    idx = np.argsort(freqs)\n",
    "    ps = get_average_spectrum(generated_trajectory)\n",
    "    ps_or = get_average_spectrum(test_trajectory.unsqueeze(0))\n",
    "\n",
    "    num_dims = generated_trajectory.shape[2]  # Number of dimensions\n",
    "\n",
    "    # Create subplots, one per dimension\n",
    "    fig, axes = plt.subplots(num_dims, 1, figsize=(8, 4 * num_dims), sharex=True)\n",
    "\n",
    "    for dim in range(num_dims):  # Loop over dimensions\n",
    "        ax = axes[dim]\n",
    "        ax.plot(freqs[idx], ps_or[0,:,dim], label=f'Original (Dim {dim +1})', linestyle=\"-\", color=\"blue\")\n",
    "        ax.plot(freqs[idx], ps[0,:,dim], label=f'Generated (Dim {dim + 1})', linestyle=\"--\", color=\"red\")\n",
    "        ax.set_ylabel(\"Power\")\n",
    "        ax.set_title(f\"Power Spectrum (Dimension {dim + 1})\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Common labels\n",
    "    axes[-1].set_xlabel(\"Frequency\")\n",
    "    plt.suptitle(\"Power Spectrum Comparison per Dimension\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.title(f\"Power Spectrum\")\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.savefig(f\"plots/{model_name}_power_spectrum.png\")\n",
    "    plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "    ps_error = power_spectrum_error(generated_trajectory, test_trajectory.unsqueeze(0))\n",
    "    print(ps_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1bef4e898a16c7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the args dictionary with values\n",
    "args63 = {\n",
    "    \"model_name\": \"Lorenz63\",\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"dim_val\": 256,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_decoder_layers\": 2,\n",
    "    \"n_encoder_layers\": 2,\n",
    "    \"dec_seq_len\": 64,  # length of input given to decoder\n",
    "    \"enc_seq_len\": 128,  # length of input given to encoder\n",
    "    \"output_seq_len\": 32,  # target sequence length\n",
    "    \"window_size\": 128 + 32,  # enc_seq_len + output_seq_len\n",
    "    \"step_size\": 10,  # Step size for moving window\n",
    "    \"in_features_encoder_linear_layer\": 512,\n",
    "    \"in_features_decoder_linear_layer\": 512,\n",
    "    \"max_seq_len\": 128,  # Same as enc_seq_len\n",
    "}\n",
    "\n",
    "\n",
    "args96 = {\n",
    "    \"model_name\": \"Lorenz96\",\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"dim_val\": 256,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_decoder_layers\": 2,\n",
    "    \"n_encoder_layers\": 2,\n",
    "    \"dec_seq_len\": 64,  # length of input given to decoder\n",
    "    \"enc_seq_len\": 128,  # length of input given to encoder\n",
    "    \"output_seq_len\": 32,  # target sequence length\n",
    "    \"window_size\": 128 + 32,  # enc_seq_len + output_seq_len\n",
    "    \"step_size\": 10,  # Step size for moving window\n",
    "    \"in_features_encoder_linear_layer\": 512,\n",
    "    \"in_features_decoder_linear_layer\": 512,\n",
    "    \"max_seq_len\": 128,  # Same as enc_seq_len\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782d7c4a91f197a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now for executing the code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710c8fe3aaa6b71",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Lorenz63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e985df8431267",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (100000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "data_path63 = \"data/lorenz63_on0.05_train.npy\"\n",
    "train_TimeSeriesTransformer(data_path=data_path63,args=args63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe181411c1ec4a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_path_train = \"data/lorenz63_on0.05_train.npy\"\n",
    "data_path = \"data/lorenz63_test.npy\"\n",
    "generate_TimeSeriesTransformer(data_path=data_path,data_path_train=data_path_train,args=args63)\n",
    "analyze_generated_trajectories(model_name=args63[\"model_name\"], data_validation_path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d1bf610c8e148",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Lorenz96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dcf3291abece5f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_path96 = \"data/lorenz96_on0.05_train.npy\"\n",
    "train_TimeSeriesTransformer(data_path=data_path96, args=args96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bbc39e495ca38",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_path_train = \"data/lorenz96_on0.05_train.npy\"\n",
    "data_path = \"data/lorenz96_test.npy\"\n",
    "generate_TimeSeriesTransformer(data_path=data_path, data_path_train=data_path_train, args=args96)\n",
    "analyze_generated_trajectories(model_name=args96[\"model_name\"], data_validation_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4dfe65-0f52-401f-b486-5d0fade294ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
